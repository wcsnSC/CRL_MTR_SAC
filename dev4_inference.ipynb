{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131ebfb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T05:56:39.334533Z",
     "start_time": "2024-03-21T05:56:38.621617Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rc('font',family='Times New Roman')\n",
    "\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import saferl_algos\n",
    "from saferl_plotter.logger import SafeLogger\n",
    "import saferl_utils\n",
    "\n",
    "import os,sys,argparse,warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "source = np.loadtxt('data_dev20.csv')\n",
    "\n",
    "\n",
    "# source = pd.read_csv('data_6_devs_.csv', sep=' ')\n",
    "# source = np.array(source)\n",
    "\n",
    "# source = pd.read_csv('data_0304_mote12_4dev.txt', sep=' ')\n",
    "# # source = source.drop('date:yyyy-mm-dd', axis = 1)\n",
    "# source = np.array(source)\n",
    "\n",
    "\n",
    "import os,sys,argparse,warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "import saferl_algos\n",
    "from saferl_plotter.logger import SafeLogger\n",
    "import saferl_utils\n",
    "\n",
    "import skimage.measure \n",
    "from sklearn import metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ef9bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T05:57:01.489197Z",
     "start_time": "2024-03-21T05:57:01.485618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dim:12\n"
     ]
    }
   ],
   "source": [
    "    # open env\n",
    "    device_num, action_dim = 4, 4\n",
    "\n",
    "    env = sample_env(source[:,:4], device_num, action_dim, M = 1)\n",
    "    env._max_episode_steps = 1000    # Done?\n",
    "    \n",
    "    state_dim = 3 * env.device_num\n",
    "    print(f\"state_dim:{state_dim}\")\n",
    "    action_dim = env.action_dim\n",
    "    max_action = env.max_action\n",
    " \n",
    "    kwargs = {\n",
    "        \"state_dim\": state_dim,\n",
    "        \"action_dim\": action_dim,\n",
    "        \"max_action\": max_action,\n",
    "        \"rew_discount\": 0.99,\n",
    "        \"tau\": 0.005,\n",
    "        \"policy_noise\": 0.2* max_action,\n",
    "        \"noise_clip\": 0.5 * max_action,\n",
    "        \"policy_freq\": 2,\n",
    "    }\n",
    "\n",
    "    kwargs_safe = {\n",
    "        \"cost_discount\": 0.99,\n",
    "        \"delta\": 0.1,                     \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdeb83a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T05:57:08.473488Z",
     "start_time": "2024-03-21T05:57:06.827271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor state_dim:12\n",
      "Actor(\n",
      "  (l1): Linear(in_features=12, out_features=256, bias=True)\n",
      "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (l3): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from saferl_algos.fac_sampler import eval_policy\n",
    "kwargs.update(kwargs_safe)\n",
    "policy = saferl_algos.fac_sampler.TD3Fac(**kwargs)\n",
    "# replay_buffer = saferl_utils.CostReplayBuffer(state_dim, action_dim)\n",
    "\n",
    "\n",
    "# replay_buffer = saferl_utils.MultiTimescaleReplayBuffer(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40ae4530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:19:22.045493Z",
     "start_time": "2024-03-21T07:19:21.988893Z"
    }
   },
   "outputs": [],
   "source": [
    "policy.load('./models_d4_w_M/dev4_uneven_seed_1_M_2_MTR_1_beta_0.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "392d22c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:19:23.768449Z",
     "start_time": "2024-03-21T07:19:23.018933Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:0: state: [2.         0.86847884 1.         2.         0.98220846 1.\n",
      " 2.         0.86847884 1.         2.         0.98220846 1.        ] device_id:3: x_: [0, 0, 0, 0] \n",
      " reward:-103.0\n",
      "time:100: state: [0.00000000e+00 3.31727795e-03 1.00000000e+00 0.00000000e+00\n",
      " 7.67168737e-04 1.00000000e+00 0.00000000e+00 3.31727795e-03\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00] device_id:3: x_: [0.7936031401857822, 1.0433262346859418, 0.7936031401857822, 1.0433262346859418] \n",
      " reward:-0.0720912076756369\n",
      "time:200: state: [0.00000000e+00 2.84338110e-03 1.00000000e+00 6.00000000e+00\n",
      " 3.82421992e-03 0.00000000e+00 0.00000000e+00 2.84338110e-03\n",
      " 1.00000000e+00 0.00000000e+00 1.52968797e-03 1.00000000e+00] device_id:3: x_: [0.7514263204830121, 1.064793010797464, 0.7514263204830121, 1.0686172307133674] \n",
      " reward:-0.21404537500089518\n",
      "time:300: state: [2.00000000e+00 1.89558740e-03 0.00000000e+00 0.00000000e+00\n",
      " 3.06635019e-03 1.00000000e+00 4.00000000e+00 1.89558740e-03\n",
      " 1.00000000e+00 0.00000000e+00 3.06635019e-03 1.00000000e+00] device_id:3: x_: [0.7542697015865696, 1.0533064025272636, 0.7542697015865696, 1.0533064025272636] \n",
      " reward:-0.09215578226049591\n",
      "time:400: state: [1.00000000e+00 9.47793701e-04 0.00000000e+00 1.00000000e+00\n",
      " 7.83442013e-04 1.00000000e+00 1.00000000e+00 9.47793701e-04\n",
      " 0.00000000e+00 3.00000000e+00 7.85766767e-04 1.00000000e+00] device_id:3: x_: [0.974631737112278, 0.9446753093781187, 0.974631737112278, 0.9431061005980368] \n",
      " reward:-8.6130829226286\n",
      "time:500: state: [1.00000000e+00 9.47793701e-04 0.00000000e+00 3.00000000e+00\n",
      " 2.41541914e-03 0.00000000e+00 1.00000000e+00 9.47793701e-04\n",
      " 1.00000000e+00 0.00000000e+00 1.60872959e-03 1.00000000e+00] device_id:3: x_: [1.076045663139163, 0.8230418685149016, 1.076045663139163, 0.8206264493704496] \n",
      " reward:-1.1979651172137034\n",
      "time:600: state: [0.         0.00236948 1.         0.         0.01753097 1.\n",
      " 0.         0.00236948 1.         2.         0.00715559 0.        ] device_id:3: x_: [1.065146035575526, 0.8814559559476735, 1.065146035575526, 0.8886115479848475] \n",
      " reward:-0.4443311059872578\n",
      "time:700: state: [1.00000000e+00 9.47793701e-04 0.00000000e+00 1.00000000e+00\n",
      " 4.67740454e-03 0.00000000e+00 1.00000000e+00 9.47793701e-04\n",
      " 0.00000000e+00 2.00000000e+00 1.24816029e-02 0.00000000e+00] device_id:3: x_: [0.9931137142854018, 0.9759734690910732, 0.9931137142854018, 0.9681692707581319] \n",
      " reward:-2.437684450429829\n",
      "time:800: state: [1.00000000e+00 2.84338110e-03 1.00000000e+00 3.00000000e+00\n",
      " 3.10819576e-03 1.00000000e+00 3.00000000e+00 2.84338110e-03\n",
      " 1.00000000e+00 0.00000000e+00 3.10819576e-03 1.00000000e+00] device_id:3: x_: [0.9262942583518, 0.9946528654584199, 0.9262942583518, 0.9915446696969834] \n",
      " reward:-0.3613190232575651\n",
      "time:900: state: [1.00000000e+00 4.73896851e-04 1.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 3.00000000e+00 2.36948425e-03\n",
      " 1.00000000e+00 4.00000000e+00 7.79257456e-03 0.00000000e+00] device_id:3: x_: [0.9016516221209682, 0.9837660436552731, 0.9035472095233398, 0.9759734690910732] \n",
      " reward:-0.646987784747661\n"
     ]
    }
   ],
   "source": [
    "device_num, action_dim = 4, 4\n",
    "\n",
    "r_weight = np.array([3, 2, 3, 2 ]) # urgency weight\n",
    "dev_spent_RBs = np.array([1, 1, 1, 1])\n",
    "\n",
    "M = 1,\n",
    "cost_weight = 100,\n",
    "\n",
    "env = sample_env(source[:, :device_num], device_num, action_dim, M, r_weight, dev_spent_RBs, cost_weight)\n",
    "\n",
    "\n",
    "# x__list = [[] for i in range(env.device_num)]\n",
    "# aoi_list = [[] for i in range(env.device_num)]\n",
    "# AoII_list = [[] for i in range(env.device_num)]\n",
    "instant_comm_load = [[] for i in range(env.device_num)]\n",
    "# Expected_AoII = [[] for i in range(env.device_num)]\n",
    "x__list = []\n",
    "aoi_list = []\n",
    "AoII_list = []\n",
    "# instant_comm_load = []\n",
    "Expected_AoII = []\n",
    "\n",
    "\n",
    "x__list= np.empty((env.device_num, 0))\n",
    "aoi_list = np.empty((env.device_num, 0))\n",
    "AoII_list = np.empty((env.device_num, 0))\n",
    "tra_data_record = np.empty((1, 0))\n",
    "\n",
    "state = np.array([0,0,1] * env.device_num)\n",
    "RB_load = np.empty((1, 0))\n",
    "\n",
    "\n",
    "sample_time = [0 for i in range(env.device_num)]\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    action = policy.select_action(np.array(state))\n",
    "\n",
    "    for dev in range(env.device_num): \n",
    "# #         action = [random.random(), random.random()]\n",
    "# #         action = np.random.rand(2) \n",
    "        if action[dev] > 0:\n",
    "            sample_time[dev] += 1\n",
    "        \n",
    "        instant_comm_load[dev].append(sample_time[dev]/(i+1))\n",
    "\n",
    "            \n",
    "    next_state, reward, done, info, = env.step(action)\n",
    "        \n",
    "    if i % 100 == 0:  print(f'time:{i}: state:', next_state, f'device_id:{dev}: x_:', env.x_, '\\n', f'reward:{reward}')\n",
    "            \n",
    "#     x__list += env.x_\n",
    "    \n",
    "    x__list =  np.append(x__list, np.array(env.x_).reshape(-1,1), axis =1)\n",
    "    aoi_list =  np.append(aoi_list, np.array(env.aoi).reshape(-1,1), axis =1)\n",
    "    AoII_list =  np.append(AoII_list, np.array(env.AoII).reshape(-1,1), axis =1)\n",
    "    action_cost = action = np.where(action > 0, 1, 0) \n",
    "    RB_load =  np.append(RB_load, np.dot(dev_spent_RBs, action).reshape(-1,1), axis =1)\n",
    "    tra_data_record = np.append(tra_data_record, action[-1].reshape(-1,1), axis =1)\n",
    "    \n",
    "#     x__list.append(env.x_)\n",
    "#     print('X__list: ', x__list,)\n",
    "#     aoi_list.append(env.aoi)\n",
    "#     AoII_list.append(env.AoII)\n",
    "\n",
    "\n",
    "#     if i > 0:\n",
    "#         Expected_AoII.append( (Expected_AoII[-1]*i + env.AoII)/(i+1) ) \n",
    "    state = next_state\n",
    "\n",
    "\n",
    "# samr040 = instant_comm_load[100:]  # 0.6 constrain    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3740ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:19:25.775872Z",
     "start_time": "2024-03-21T07:19:25.772184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample times: [696, 637, 626, 948]\n",
      "tot_RB_cost: 2907\n",
      "avg_RB_cost: 2.907\n",
      "tot_RB_cost/M/steps: [2.907]\n",
      "avg_aoii: [0.062 0.213 0.103 0.07 ]\n",
      "w_expected_aoii: 0.026525\n",
      "[0.0042, 0.01, 0.0044, 0.0048]\n",
      "0.00585\n"
     ]
    }
   ],
   "source": [
    "print('sample times:', sample_time)\n",
    "print('tot_RB_cost:', np.dot(dev_spent_RBs, sample_time) )\n",
    "print('avg_RB_cost:', np.dot(dev_spent_RBs, sample_time) / len(x__list[0]) )\n",
    "print('tot_RB_cost/M/steps:', np.dot(dev_spent_RBs, sample_time) / env.M / len(x__list[0]) )\n",
    "\n",
    "# print('RB_cost', np.dot(env.r_weight, sample_time) )\n",
    "print('avg_aoii:', AoII_list.mean(axis = 1))\n",
    "w_expected_aoii = np.dot(env.r_weight, AoII_list.mean(axis = 1)) / env.device_num\n",
    "print('w_expected_aoii:', w_expected_aoii)\n",
    "\n",
    "\n",
    "nrmse_v = []\n",
    "for dev in range(device_num):\n",
    "    nrmse_  = skimage.metrics.normalized_root_mse(source[30:x__list.shape[1], dev],\n",
    "                                           np.array(x__list[dev, 30:].T) * env.source_mean[dev])\n",
    "    nrmse_v.append(nrmse_)\n",
    "b = [float('{:.4f}'.format(i)) for i in nrmse_v]    \n",
    "print(b)\n",
    "print(sum(b) / len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a768f7e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:03:39.639800Z",
     "start_time": "2024-03-21T06:03:39.637164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9058371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:01:51.170850Z",
     "start_time": "2024-03-21T06:01:51.162466Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class sample_env():\n",
    "    def __init__(\n",
    "        self,\n",
    "        source,\n",
    "        device_num,\n",
    "        action_dim=1,\n",
    "        M = 30,\n",
    "        \n",
    "        # r_weight = np.array([3, 2, 3, 2, 1, 1]), # urgency weight\n",
    "        # dev_spent_RBs = np.array([1, 1, 1, 1, 5, 5]), \n",
    "\n",
    "        r_weight = np.array([5, 2, 5, 2]), # urgency weight\n",
    "        dev_spent_RBs = np.array([1, 1, 1, 1 ]), \n",
    "\n",
    "        cost_weight = int(5e1),\n",
    "        max_action=1,\n",
    "        delta=1,\n",
    "\n",
    "        rew_discount=0.99,\n",
    "        cost_discount=0.99,\n",
    "        tau=0.005,\n",
    "        policy_noise=0.2,\n",
    "        noise_clip=0.5,\n",
    "        policy_freq=2,\n",
    "        delay = 2,\n",
    "        prob_pass = 0.75,\n",
    "        ksi = 0.0001\n",
    "    ):\n",
    "\n",
    "\n",
    "        self.device_num = device_num\n",
    "        self.action_dim = action_dim\n",
    "        self.max_action = max_action\n",
    "\n",
    "        self._max_episode_steps = int(9e3)\n",
    "        self.tau  = tau\n",
    "        \n",
    "        self.prob_pass = prob_pass\n",
    "        self.delay = delay\n",
    "        self.ksi = ksi\n",
    "        self.t = 0\n",
    "        self.aoi = [1 for i in range(self.device_num)]\n",
    "        self.x_ = [0 for i in range(self.device_num)]\n",
    "        self.AoII = np.array([1 for i in range(self.device_num)])\n",
    "        self.arrive_times =[[] for i in range(self.device_num)]\n",
    "        self.send_times = [[] for i in range(self.device_num)]\n",
    "        self.last_recv_t = [0 for i in range(self.device_num)]\n",
    "        self.source_mean = source.mean(axis=0)\n",
    "        self.source = source/self.source_mean\n",
    "        self.error_indicator = [False for i in range(self.device_num)] \n",
    "\n",
    "\n",
    "        self.r_weight = np.array(r_weight) / np.sum(r_weight) \n",
    "        self.dev_spent_RBs = dev_spent_RBs\n",
    "        self.M = M\n",
    "        self.cost_weight = cost_weight\n",
    "\n",
    "        self.done = False\n",
    "        self.reset_next_state_as = [[] for i in range(self.device_num)]\n",
    "\n",
    "        \n",
    "        \n",
    "    def step(self, action = [0,0]):\n",
    "        all_dev_state = [[] for i in range(self.device_num)]\n",
    "        for dev in range(self.device_num):        \n",
    "            x = self.source[self.t, dev]\n",
    "            if action[dev] > 0:\n",
    "                self.send_times[dev].append(self.t)\n",
    "                self.arrive_times[dev].append(self.t + self.delay)\n",
    "\n",
    "            # loss pkg?     \n",
    "            pkg_lost = np.random.uniform(0, 1) >= self.prob_pass\n",
    "\n",
    "            gamma_t = 0 if pkg_lost else 1 \n",
    "            \n",
    "            error = abs(self.x_[dev] - x) \n",
    "\n",
    "            if dev < 16 and dev % 2 == 0:\n",
    "                self.error_indicator[dev] = error / x > 1e-2     # temp   1e-1  4e-2\n",
    "            if dev < 16 and dev % 2 == 1:\n",
    "                self.error_indicator[dev] = error / x >= 1e-2   # humi   1e-1    4e-2\n",
    "            elif dev >= 16:\n",
    "                self.error_indicator[dev] = error > 5e-2         # traj  1e-1   3e-1\n",
    "\n",
    "            # self.error_indicator[dev] = error >= self.ksi \n",
    "\n",
    "            # AoI evoluation, only when pkg is received   \n",
    "            if pkg_lost == False and self.t in self.arrive_times[dev]:\n",
    "                self.aoi[dev] = self.t - self.send_times[dev][-1] # update aoi\n",
    "                # del self.send_times[0]\n",
    "                self.last_recv_t[dev] = self.t\n",
    "                self.x_[dev] = x # update estimation result\n",
    "            else: \n",
    "                self.aoi[dev] += 1\n",
    "\n",
    "            self.AoII[dev] = self.aoi[dev] * (1 if self.error_indicator[dev] else 0)\n",
    "\n",
    "            if self.t in self.arrive_times[dev]:\n",
    "                self.arrive_times[dev].remove(self.t)\n",
    "            if self.t - self.delay in self.send_times[dev]:\n",
    "                self.send_times[dev].remove(self.t - self.delay)\n",
    "            \n",
    "            dev_state = np.array([self.aoi[dev], error,  gamma_t])\n",
    "            all_dev_state[dev] = dev_state\n",
    "        self.t += 1\n",
    "\n",
    "\n",
    "        next_state = 1 \n",
    "        reward = 1\n",
    "        self.done =  0 if self.t < self._max_episode_steps  else 1\n",
    "        info = \"step\"\n",
    "\n",
    "        if self.t < self._max_episode_steps:\n",
    "            pass\n",
    "        else:\n",
    "            self.reset_next_state_as = np.array(all_dev_state).reshape(3 * self.device_num)\n",
    "\n",
    "        RB_cost = np.dot(dev_spent_RBs.T, action)\n",
    "        RB_cost = RB_cost - self.M if RB_cost > self.M else 0\n",
    "        return  np.array(all_dev_state).reshape(3 * self.device_num), \\\n",
    "                -100 * skimage.metrics.normalized_root_mse(source[self.t, : self.device_num], \\\n",
    "                    np.array(self.x_) * env.source_mean[:])  -5 * np.max(env.AoII * env.r_weight) , \\\n",
    "                self.done, info\n",
    "                # np.dot( self.r_weight ,(-1) * self.AoII.reshape(self.device_num) ), \\\n",
    "                # (-1 * np.max(env.AoII * env.r_weight) ), \\\n",
    "                # -1000 * skimage.metrics.normalized_root_mse(source[self.t, :], \\\n",
    "                #     np.array(self.x_) * env.source_mean[:]) + (-1 * np.max(env.AoII * env.r_weight) ),  \\\n",
    "\n",
    "\n",
    "                \n",
    "        # np.array([self.aoi, error,  gamma_t]), -self.AoII, done, info \n",
    "        # return next_state, reward , done, info, pkg_lost, AoII, self.t, self.arrive_times, self.send_times, self.aoi, self.x_\n",
    "    \n",
    "    def reset(self):\n",
    "        self.t = 0 \n",
    "        self.arrive_times =[[] for i in range(self.device_num)]\n",
    "        self.send_times = [[] for i in range(self.device_num)]\n",
    "        if self.done:\n",
    "            reset_state = self.reset_next_state_as\n",
    "        else: reset_state = np.array([-1, 0, 0]*self.device_num)\n",
    "        return [reset_state, self.t]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
